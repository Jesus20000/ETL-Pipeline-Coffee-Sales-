# â˜• Coffee Sales ETL Pipeline

This project demonstrates a beginner-friendly ETL (Extract, Transform, Load) pipeline for coffee shop sales data.  
It reads raw data from a CSV file, cleans and transforms it using Python (Pandas), and loads the results into a PostgreSQL database.

---

## ğŸ”§ Tech Stack

- Python
- Pandas
- PostgreSQL
- SQLAlchemy
- pyarrow (for saving parquet files)

---

## ğŸ“ Project Structure

```
coffee-sales-etl-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw input data (CSV)
â”‚   â””â”€â”€ processed/        # Cleaned output data (Parquet)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py        # Read CSV file
â”‚   â”œâ”€â”€ transform.py      # Data cleaning + transformation
â”‚   â”œâ”€â”€ load.py           # Load to PostgreSQL
â”‚   â””â”€â”€ etl.py            # Orchestration script
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸš€ How to Run

1. Clone the repository:

```bash
git clone https://github.com/yourusername/coffee-sales-etl-pipeline.git
cd coffee-sales-etl-pipeline
```

2. Create a virtual environment and activate it:

```bash
python -m venv .venv
.venv\Scripts\activate  # on Windows
```

3. Install the required libraries:

```bash
pip install -r requirements.txt
```

4. Place your raw CSV inside `data/raw/index_1.csv`

5. Update your PostgreSQL credentials in `etl.py`

6. Run the ETL pipeline:

```bash
python src/etl.py
```

---

## âœ… What It Does

- **Extract**:
  - Reads a CSV from `data/raw/`

- **Transform**:
  - Drops rows with missing `card`
  - Converts datetime column
  - Extracts hour into a new column
  - Adds binary column `is_cash`

- **Load**:
  - Saves to Parquet in `data/processed/`
  - Loads cleaned data into PostgreSQL (`coffee_sales` table)

---

## ğŸ™Œ Author

Isa Zeynalov â€“ Data Analytics Engineer
Letâ€™s connect on [LinkedIn](https://www.linkedin.com/in/isa-zeynalov-56a8a31a9/)

